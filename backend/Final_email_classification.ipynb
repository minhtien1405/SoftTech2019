{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sys, email\n",
    "import pandas as pd \n",
    "import math\n",
    "import sys\n",
    "import csv\n",
    "maxInt = sys.maxsize\n",
    "import re\n",
    "\n",
    "while True:\n",
    "    # decrease the maxInt value by factor 10 \n",
    "    # as long as the OverflowError occurs.\n",
    "\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRE = ['require', 'required', 'need', 'want', 'prefer']\n",
    "\n",
    "SYSTEM = ['registration', 'scholarship', 'signature', 'contract', 'deadline', 'scanned', 'copy']\n",
    "\n",
    "ACCOMODATION = ['accomodation', 'apartment', 'flat', 'rent','rental', 'payment', 'dorm','tenant']\n",
    "\n",
    "MONEY_RELATE = ['pay', 'insurance', 'tax', 'costs', 'paid', 'benefits', 'budget', 'income', 'spending', 'paying', 'fees', 'taxes', 'savings', 'payments', 'expenses', 'bills', 'retirement', 'compensation', 'contracts', 'salary', 'liability', 'employer', 'expense', 'employers', 'pays', 'wage', 'pension', 'wages', 'incentive', 'incentives', 'salaries', 'owe', 'taxpayers', 'payroll', 'insured', 'taxpayer', 'premiums', 'expenditure', 'taxation', 'subsidies', 'liabilities', 'dividends', 'insurers', 'deduction', 'paycheck', 'incomes', 'reimbursement', 'insurer', 'unpaid', 'deductible', 'dues', 'pensions', 'beneficiaries', 'deferred', 'taxable', 'upfront', 'entitlement', 'beneficiary', 'scholarship']\n",
    "\n",
    "PROBLEM = ['law', 'rights', 'rules', 'federal', 'rule', 'laws', 'proposed', 'legislation', 'regulations', 'limits', 'adopted', 'enforcement', 'provisions', 'regulation', 'provision', 'ban', 'restrictions', 'strict', 'amendment', 'prohibited', 'imposed', 'violators', 'stipulates', 'instituting', 'polices', 'legislated', 'exempts', 'exempting']\n",
    "\n",
    "STUDY = ['code', 'language', 'simulation', 'number', 'rules', 'example', 'form', 'test', 'error', 'period', 'projects', 'members', 'discussion', 'links', 'research', 'notice', 'description', 'statement', 'value', 'events', 'library', 'numbers', 'complete', 'credit', 'note', 'member', 'instructions', 'students', 'classes', 'articles', 'lessons', 'teams', 'roles', 'presentation', 'dates', 'master', 'credits', 'sessions', 'draft', 'appointment', 'correction']\n",
    "\n",
    "EMOTION = ['confused', 'angry', 'nervous', 'desperate', 'shocked', 'frustrated', 'stressed', 'depressed', 'anxious', 'exhausted', 'unhappy', 'suspicious', 'overwhelmed', 'ashamed', 'unsure', 'unaware', 'embarrassed', 'reluctant', 'offended', 'relieved', 'skeptical', 'annoyed', 'cautious', 'distracted', 'fascinated', 'confronted', 'disturbed', 'stunned', 'intrigued', 'distressed', 'stubborn', 'terrified', 'wary', 'helpless', 'frightened', 'discouraged', 'paranoid', 'weary', 'fearful', 'restless', 'amused', 'irritated', 'hesitant', 'insecure', 'impatient', 'intimidated', 'disgusted', 'indifferent', 'freaked', 'outsider', 'aroused', 'behaving', 'horrified', 'oblivious', 'fearing', 'powerless', 'saddened', 'astonished', 'dissatisfied', 'humbled', 'understandably', 'appalled', 'envious', 'timid', 'baffled', 'unprepared', 'cranky', 'giddy', 'pessimistic', 'angered', 'disgruntled', 'panicked', 'preoccupied', 'reassured', 'conflicted', 'aback', 'perplexed', 'complacent', 'doubting', 'flattered', 'apprehensive', 'enraged', 'hapless', 'defiant', 'sympathize', 'stumped', 'dismayed', 'elated', 'unsettled', 'meek', 'enamored', 'touchy', 'disinterested', 'apologetic', 'coy', 'averse', 'enthused', 'irate', 'displeased', 'overreacting', 'frazzled', 'unmoved', 'testy', 'panicky', 'irrationally', 'unfazed', 'heartened', 'unnerved', 'dissappointed']\n",
    "\n",
    "SECURITY_SPAM_ALERTS=['accidental','anthrax','anti','antibiotic','antibiotics','assaulted','attacked','attacker','attackers','auth','authenticated','authentication','avoid','avoidance','avoided','avoiding','bacteria','besieged','biometric','bioterrorism','blocking','boarded','bodyguards','botched','captive','captives','captured','chased','commandeered','compromised','confronted','contagious','cornered','culprit','damage','damaging','danger','dangerous','dangers','destroying','destructive','deterrent','detrimental','disruptive','electrocuted','eliminate','eliminating','encroachment','encrypted','encryption','epidemic','escape','escaped','escapee','escaping','expose','exposed','exposing','fatally','feared','fled','flee','fleeing','flu','foiled','freed','germ','germs','guarded','guarding','guards','hapless','harassed','harm','harmful','harmless','harsh','hepatitis','hid','hijacked','hijacker','hijackers','hiv','hostage','hostages','hunted','immune','immunity','immunization','imprisoned','improper','inadvertent','infect','infected','infecting','infection','infections','infectious','injuring','intentional','interference','interfering','intruders','intrusion','intrusive','invaded','isolates','kidnapped','limiting','login','logins','logon','lured','malaria','malicious','masked','minimise','minimize','minimizing','misuse','mite','mitigating','mosquito','motorcade','nuisance','offending','outbreak','overrun','passcode','password','passwords','plaintext','pneumonia','policeman','potentially','prevent','prevented','preventing','prevents','prone','protect','protected','protecting','protection','protects','quarantine','raided','ransom','raped','refuge','removing','rescued','rescuing','resisting','risks','robbed','runaway','safeguard','secret','secrets','seized','sensitive','server','shielding','smallpox','spam','spores','stolen','strain','strains','stranded','strep','summoned','susceptible','swine','threat','threatened','threatening','threats','thwarted','tortured','trapped','unaccounted','undesirable','unhealthy','unidentified','unintended','unintentional','unnamed','unnecessary','unprotected','unsafe','unwanted','unwelcome','user','username','vaccine','vaccines','viral','virus','viruses','vulnerability','vulnerable','whereabouts','withstand','wounded']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/estimators/dnn.py:378: multi_class_head (from tensorflow.contrib.learn.python.learn.estimators.head) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.contrib.estimator.*_head.\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:1180: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:427: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fbc65edb710>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/var/folders/t3/h3nhhgs91gx424npw04bv5xc0000gn/T/tmpfyeo1kb0', '_session_creation_timeout_secs': 7200}\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/estimators/head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/t3/h3nhhgs91gx424npw04bv5xc0000gn/T/tmpfyeo1kb0/model.ckpt.\n",
      "INFO:tensorflow:loss = 3.228724, step = 1\n",
      "INFO:tensorflow:global_step/sec: 19.2025\n",
      "INFO:tensorflow:loss = 0.4571187, step = 101 (5.208 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into /var/folders/t3/h3nhhgs91gx424npw04bv5xc0000gn/T/tmpfyeo1kb0/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.26908368.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-02T20:04:00Z\n",
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/t3/h3nhhgs91gx424npw04bv5xc0000gn/T/tmpfyeo1kb0/model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-02-20:04:01\n",
      "INFO:tensorflow:Saving dict for global step 200: accuracy = 0.9411758, global_step = 200, loss = 0.26646647\n",
      "accuracy: 0.9411758\n",
      "global_step: 200\n",
      "loss: 0.26646647\n",
      "WARNING:tensorflow:From <ipython-input-3-d7d89ce82c4f>:115: calling DNNClassifier.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with as_iterable=False is deprecated and will be removed after 2016-09-15.\n",
      "Instructions for updating:\n",
      "The default behavior of predict() is changing. The default value for\n",
      "as_iterable will change to True, and then the flag will be removed\n",
      "altogether. The behavior of this flag is described below.\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py:574: calling DNNClassifier.predict (from tensorflow.contrib.learn.python.learn.estimators.dnn) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_classes, or set `outputs` argument.\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/estimators/dnn.py:427: calling DNNClassifier.predict_classes (from tensorflow.contrib.learn.python.learn.estimators.dnn) with as_iterable=False is deprecated and will be removed after 2016-09-15.\n",
      "Instructions for updating:\n",
      "The default behavior of predict() is changing. The default value for\n",
      "as_iterable will change to True, and then the flag will be removed\n",
      "altogether. The behavior of this flag is described below.\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/estimators/dnn.py:463: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with as_iterable is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/t3/h3nhhgs91gx424npw04bv5xc0000gn/T/tmpfyeo1kb0/model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[7 7 6 ... 6 0 3]\n",
      "buckets found: {0, 1, 3, 4, 5, 6, 7}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12276</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>90</td>\n",
       "      <td>14</td>\n",
       "      <td>12636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>775</td>\n",
       "      <td>460</td>\n",
       "      <td>407</td>\n",
       "      <td>323</td>\n",
       "      <td>208</td>\n",
       "      <td>2182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>28</td>\n",
       "      <td>59</td>\n",
       "      <td>65</td>\n",
       "      <td>64</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>15074</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>15152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>1956</td>\n",
       "      <td>728</td>\n",
       "      <td>748</td>\n",
       "      <td>513</td>\n",
       "      <td>4143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>98</td>\n",
       "      <td>16714</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>16882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>14569</td>\n",
       "      <td>0</td>\n",
       "      <td>14721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>55</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>27945</td>\n",
       "      <td>28059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>All</td>\n",
       "      <td>12448</td>\n",
       "      <td>11</td>\n",
       "      <td>16461</td>\n",
       "      <td>2706</td>\n",
       "      <td>17998</td>\n",
       "      <td>15815</td>\n",
       "      <td>28774</td>\n",
       "      <td>94213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      0   1      3     4      5      6      7    All\n",
       "Actual                                                       \n",
       "0          12276   0    187     2     67     90     14  12636\n",
       "1              7   2    775   460    407    323    208   2182\n",
       "2              3   0    219    28     59     65     64    438\n",
       "3             23   1  15074    45      2      0      7  15152\n",
       "4             32   0    166  1956    728    748    513   4143\n",
       "5             14   3     17    98  16714     13     23  16882\n",
       "6             73   4     11    62      2  14569      0  14721\n",
       "7             20   1     12    55     19      7  27945  28059\n",
       "All        12448  11  16461  2706  17998  15815  28774  94213"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################################\n",
    "# TensorFlow Deep Classifier \n",
    "####################################################\n",
    "# https://www.tensorflow.org/api_docs/python/tf/contrib/learn/DNNClassifier\n",
    "# create a wide and deep model and also predict a few entries\n",
    "\n",
    "model_ready_data = pd.read_csv('../email_classification_df.csv') \n",
    "\n",
    "# https://stackoverflow.com/questions/38250710/how-to-split-data-into-3-sets-train-validation-and-test\n",
    "# (60% - train set, 20% - validation set, 20% - test set)\n",
    "df_train, df_test, df_val = np.split(model_ready_data.sample(frac=1), [int(.6*len(model_ready_data)), int(.8*len(model_ready_data))])\n",
    "\n",
    "# Continuous base columns\n",
    "content_length = tf.contrib.layers.real_valued_column(\"content_length\")\n",
    "content_word_count = tf.contrib.layers.real_valued_column(\"content_word_count\")\n",
    "subject_length = tf.contrib.layers.real_valued_column(\"subject_length\")\n",
    "subject_word_count = tf.contrib.layers.real_valued_column(\"subject_word_count\")\n",
    "group_REQUIRE = tf.contrib.layers.real_valued_column(\"group_REQUIRE\")\n",
    "group_SYSTEM = tf.contrib.layers.real_valued_column(\"group_SYSTEM\")\n",
    "group_ACCOMODATION = tf.contrib.layers.real_valued_column(\"group_ACCOMODATION\")\n",
    "group_MONEY_RELATE = tf.contrib.layers.real_valued_column(\"group_MONEY_RELATE\")\n",
    "group_PROBLEM = tf.contrib.layers.real_valued_column(\"group_PROBLEM\")\n",
    "group_STUDY = tf.contrib.layers.real_valued_column(\"group_STUDY\")\n",
    "group_EMOTION = tf.contrib.layers.real_valued_column(\"group_EMOTION\")\n",
    "group_SECURITY_SPAM_ALERTS = tf.contrib.layers.real_valued_column(\"group_SECURITY_SPAM_ALERTS\")\n",
    "content_length_bucket = tf.contrib.layers.bucketized_column(content_length, boundaries=[100, 200, 300, 400])\n",
    "subject_length_bucket = tf.contrib.layers.bucketized_column(subject_length, boundaries=[10,15, 20, 25, 30])\n",
    "\n",
    "# Categorical base columns\n",
    "is_AM_sparse_column = tf.contrib.layers.sparse_column_with_keys(column_name=\"is_AM\", keys=[\"yes\", \"no\"])\n",
    "# is_AM = tf.contrib.layers.one_hot_column(is_AM_sparse_column)\\\n",
    "is_weekday_sparse_column = tf.contrib.layers.sparse_column_with_keys(column_name=\"is_weekday\", keys=[\"yes\", \"no\"])\n",
    "# is_weekday = tf.contrib.layers.one_hot_column(is_weekday_sparse_column)\n",
    "\n",
    "categorical_columns = [is_AM_sparse_column, is_weekday_sparse_column, content_length_bucket, subject_length_bucket] \n",
    "\n",
    "deep_columns = [content_length, content_word_count, subject_length, subject_word_count,\n",
    "               group_REQUIRE, group_SYSTEM , group_ACCOMODATION, group_MONEY_RELATE, group_PROBLEM, group_STUDY, group_EMOTION,group_SECURITY_SPAM_ALERTS]\n",
    " \n",
    "simple_columns = [group_REQUIRE, group_SYSTEM , group_ACCOMODATION, group_MONEY_RELATE, group_PROBLEM, group_STUDY, group_EMOTION,group_SECURITY_SPAM_ALERTS]\n",
    "\n",
    "import tempfile\n",
    "model_dir = tempfile.mkdtemp()\n",
    "classifier = tf.contrib.learn.DNNClassifier(feature_columns=simple_columns,\n",
    "                                hidden_units=[20, 20],\n",
    "                                n_classes=8,\n",
    "                                model_dir=model_dir,)\n",
    "\n",
    "# Define the column names for the data sets.\n",
    "COLUMNS = ['content_length',\n",
    " 'content_word_count',\n",
    " 'group_REQUIRE',\n",
    " 'group_SYSTEM',\n",
    " 'group_ACCOMODATION',\n",
    " 'group_MONEY_RELATE',\n",
    " 'group_PROBLEM',\n",
    " 'group_STUDY',\n",
    " 'group_EMOTION',\n",
    " 'group_SECURITY_SPAM_ALERTS',\n",
    " 'is_AM',\n",
    " 'is_weekday',\n",
    " 'subject_length',\n",
    " 'subject_word_count',\n",
    " 'outcome']\n",
    "LABEL_COLUMN = 'outcome'\n",
    "CATEGORICAL_COLUMNS = [\"is_AM\", \"is_weekday\"]\n",
    "CONTINUOUS_COLUMNS = ['content_length',\n",
    " 'content_word_count',\n",
    " 'group_REQUIRE',\n",
    " 'group_SYSTEM',\n",
    " 'group_ACCOMODATION',\n",
    " 'group_MONEY_RELATE',\n",
    " 'group_PROBLEM',\n",
    " 'group_STUDY',\n",
    " 'group_EMOTION',\n",
    " 'group_SECURITY_SPAM_ALERTS',\n",
    " 'subject_length',\n",
    " 'subject_word_count']\n",
    "\n",
    "LABELS = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    " \n",
    "def input_fn(df):\n",
    "  # Creates a dictionary mapping from each continuous feature column name (k) to\n",
    "  # the values of that column stored in a constant Tensor.\n",
    "  continuous_cols = {k: tf.constant(df[k].values)\n",
    "                     for k in CONTINUOUS_COLUMNS}\n",
    "  # Creates a dictionary mapping from each categorical feature column name (k)\n",
    "  # to the values of that column stored in a tf.SparseTensor.\n",
    "  categorical_cols = {k: tf.SparseTensor(\n",
    "      indices=[[i, 0] for i in range(df[k].size)],\n",
    "      values=df[k].values,\n",
    "      dense_shape=[df[k].size, 1])\n",
    "                      for k in CATEGORICAL_COLUMNS}\n",
    "  # Merges the two dictionaries into one.\n",
    "  feature_cols = dict(continuous_cols.items()).copy()\n",
    "  feature_cols.update(dict(categorical_cols.items()))\n",
    "  \n",
    "  # Converts the label column into a constant Tensor.\n",
    "  label = tf.constant(df[LABEL_COLUMN].values)\n",
    "  # Returns the feature columns and the label.\n",
    "  return feature_cols, label\n",
    "\n",
    "def train_input_fn():\n",
    "  return input_fn(df_train)\n",
    "\n",
    "def eval_input_fn():\n",
    "  return input_fn(df_test)\n",
    "# After reading in the data, you can train and evaluate the model:\n",
    "\n",
    "classifier.fit(input_fn=train_input_fn, steps=200)\n",
    "results = classifier.evaluate(input_fn=eval_input_fn, steps=1)\n",
    "for key in sorted(results):\n",
    "    print(\"%s: %s\" % (key, results[key]))\n",
    "\n",
    "y_pred = classifier.predict(input_fn=lambda: input_fn(df_val), as_iterable=False)\n",
    "print(y_pred)\n",
    "\n",
    "print('buckets found:',set(y_pred))\n",
    "\n",
    "# # confusion matrix analysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(df_val[LABEL_COLUMN], y_pred)\n",
    "pd.crosstab(df_val[LABEL_COLUMN], y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def scrub_text(subject_to_predict, content_to_predict, email_group):\n",
    "  # prep text\n",
    "  subject_to_predict = subject_to_predict.lower()\n",
    "  pattern = re.compile('[^a-z]')\n",
    "  subject_to_predict = re.sub(pattern, ' ', subject_to_predict)\n",
    "  pattern = re.compile('\\s+')\n",
    "  subject_to_predict = re.sub(pattern, ' ', subject_to_predict) \n",
    "  \n",
    "  content_to_predict = content_to_predict.lower()\n",
    "  pattern = re.compile('[^a-z]')\n",
    "  content_to_predict = re.sub(pattern, ' ', content_to_predict)\n",
    "  pattern = re.compile('\\s+')\n",
    "  content_to_predict = re.sub(pattern, ' ', content_to_predict) \n",
    "  \n",
    "  # get bag-of-words\n",
    "  words_groups = []\n",
    "  text = subject_to_predict + ' ' + content_to_predict\n",
    "  for group_id in range(len(email_group)):\n",
    "    work_group = []\n",
    "    print('Working bag number:', str(group_id))\n",
    "    top_words = email_group[group_id]\n",
    "    work_group.append(len([w for w in text.split() if w in set(top_words)]))\n",
    "    words_groups.append(work_group)\n",
    "\n",
    "  # count emails per category group and feature engineering\n",
    "  raw_text = []\n",
    "  subject_length = []\n",
    "  subject_word_count = []\n",
    "  content_length = []\n",
    "  content_word_count = []\n",
    "  is_am_list = []\n",
    "  is_weekday_list = []\n",
    "  group_REQUIRE = []\n",
    "  group_SYSTEM = []\n",
    "  group_ACCOMODATION = []\n",
    "  group_MONEY_RELATE = []\n",
    "  group_PROBLEM = []\n",
    "  group_STUDY = []\n",
    "  group_EMOTION = []\n",
    "  group_SECURITY_SPAM_ALERTS = []\n",
    "  final_outcome = []\n",
    "  \n",
    "  cur_time_stamp = datetime.datetime.now()\n",
    "  print(\"\\n \\n\")\n",
    "  print(text)\n",
    "  raw_text.append(text)\n",
    "  group_REQUIRE.append(words_groups[0])\n",
    "  group_SYSTEM.append(words_groups[1]) \n",
    "  group_ACCOMODATION.append(words_groups[2])\n",
    "  group_MONEY_RELATE.append(words_groups[3])\n",
    "  group_PROBLEM.append(words_groups[4])\n",
    "  group_STUDY.append(words_groups[5])\n",
    "  group_EMOTION.append(words_groups[6])\n",
    "  group_SECURITY_SPAM_ALERTS.append(words_groups[7]) \n",
    "  outcome_tots = [words_groups[0], words_groups[1], words_groups[2],\n",
    "    words_groups[3], words_groups[4], words_groups[5], words_groups[6], words_groups[7]] \n",
    "  final_outcome.append(outcome_tots.index(max(outcome_tots)))\n",
    "    \n",
    "  subject_length.append(len(subject_to_predict))\n",
    "  subject_word_count.append(len(subject_to_predict.split()))\n",
    "  content_length.append(len(content_to_predict))\n",
    "  content_word_count.append(len(content_to_predict.split()))\n",
    "  dt = cur_time_stamp\n",
    "  is_am = 'no'\n",
    "  if (dt.time() < datetime.time(12)): is_am = 'yes'\n",
    "  is_am_list.append(is_am)\n",
    "  is_weekday = 'no'\n",
    "  if (dt.weekday() < 6): is_weekday = 'yes'\n",
    "  is_weekday_list.append(is_weekday)\n",
    " \n",
    "  # add simple engineered features?\n",
    "  training_set = pd.DataFrame({\n",
    "                \"raw_text\":raw_text,\n",
    "                \"group_REQUIRE\":group_REQUIRE[0],\n",
    "                \"group_SYSTEM\":group_SYSTEM[0],\n",
    "                \"group_ACCOMODATION\":group_ACCOMODATION[0],\n",
    "                \"group_MONEY_RELATE\":group_MONEY_RELATE[0],\n",
    "                \"group_PROBLEM\":group_PROBLEM[0],\n",
    "                \"group_STUDY\":group_STUDY[0],\n",
    "                \"group_EMOTION\":group_EMOTION[0],\n",
    "                \"group_SECURITY_SPAM_ALERTS\": group_SECURITY_SPAM_ALERTS[0],\n",
    "                \"subject_length\":subject_length,\n",
    "                \"subject_word_count\":subject_word_count,\n",
    "                \"content_length\":content_length,\n",
    "                \"content_word_count\":content_word_count,\n",
    "                \"is_AM\":is_am_list,\n",
    "                \"is_weekday\":is_weekday_list,\n",
    "                \"outcome\":final_outcome})\n",
    "\n",
    "\n",
    "  return(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_to_predict = \"Spam\"\n",
    "content_to_predict = \"Hello! I send you some viruses! Can you see this\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_to_predict = \"health insurace\"\n",
    "content_to_predict = \"I want to ask you about the documents required for health insurance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_to_predict = \"Job\"\n",
    "content_to_predict = \"I am looking for the job to work to earn some extra money. My monthly payments is really high\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working bag number: 0\n",
      "Working bag number: 1\n",
      "Working bag number: 2\n",
      "Working bag number: 3\n",
      "Working bag number: 4\n",
      "Working bag number: 5\n",
      "Working bag number: 6\n",
      "Working bag number: 7\n",
      "\n",
      " \n",
      "\n",
      "job i am looking for the job to work to earn some extra money my monthly payments is really high\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/t3/h3nhhgs91gx424npw04bv5xc0000gn/T/tmpfyeo1kb0/model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Forward request to: Money Sector\n"
     ]
    }
   ],
   "source": [
    "email_group = [REQUIRE, SYSTEM, ACCOMODATION, MONEY_RELATE, PROBLEM, STUDY, EMOTION, SECURITY_SPAM_ALERTS]\n",
    "scrubbed_entry = scrub_text(subject_to_predict, content_to_predict, email_group)\n",
    "\n",
    "y_pred = classifier.predict(input_fn=lambda: input_fn(scrubbed_entry), as_iterable=False)\n",
    "#print(y_pred)\n",
    "\n",
    "email_group_names = ['Require/Help Sector', 'System Sector', 'Accomodation Sector', 'Money Sector', 'Problem Sector', 'Study Sector', 'Emotion Sector', 'Marked as spam']\n",
    "\n",
    "print('Forward request to: ' +  email_group_names[y_pred[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need help with registration\n",
      "\n",
      "Please propose a timeslot -- Sent from my Android device with K-9 Mail. Please excuse my brevity.\n"
     ]
    }
   ],
   "source": [
    "f=open(\"lastEmail.txt\",\"r\")\n",
    "subject_to_predict = f.readline()\n",
    "print(subject_to_predict)\n",
    "sender = f.readline()\n",
    "content_to_predict = f.readline()\n",
    "print(content_to_predict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working bag number: 0\n",
      "Working bag number: 1\n",
      "Working bag number: 2\n",
      "Working bag number: 3\n",
      "Working bag number: 4\n",
      "Working bag number: 5\n",
      "Working bag number: 6\n",
      "Working bag number: 7\n",
      "\n",
      " \n",
      "\n",
      "i need help with registration  please propose a timeslot sent from my android device with k mail please excuse my brevity \n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/t3/h3nhhgs91gx424npw04bv5xc0000gn/T/tmpfyeo1kb0/model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "scrubbed_entry = scrub_text(subject_to_predict, content_to_predict, email_group)\n",
    "\n",
    "y_pred = classifier.predict(input_fn=lambda: input_fn(scrubbed_entry), as_iterable=False)\n",
    "f2=open(\"latestEmailFlaged.txt\",\"w\")\n",
    "f2.write(\"Forward email to:\" + email_group_names[y_pred[0]] +\". Subject: \" + subject_to_predict )\n",
    "f2.write(str(y_pred[0]) + \"\\n\")\n",
    "f2.write(sender)\n",
    "f2.write(content_to_predict)\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
